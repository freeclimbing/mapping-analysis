package org.mappinganalysis.io;import com.google.common.primitives.Doubles;import org.apache.flink.api.common.functions.FilterFunction;import org.apache.flink.api.common.functions.FlatJoinFunction;import org.apache.flink.api.common.functions.GroupReduceFunction;import org.apache.flink.api.common.typeinfo.BasicTypeInfo;import org.apache.flink.api.java.DataSet;import org.apache.flink.api.java.ExecutionEnvironment;import org.apache.flink.api.java.io.jdbc.JDBCInputFormat;import org.apache.flink.api.java.operators.CoGroupOperator;import org.apache.flink.api.java.operators.GroupReduceOperator;import org.apache.flink.api.java.operators.MapOperator;import org.apache.flink.api.java.tuple.Tuple2;import org.apache.flink.api.java.tuple.Tuple3;import org.apache.flink.api.java.tuple.Tuple4;import org.apache.flink.api.java.typeutils.TupleTypeInfo;import org.apache.flink.graph.Edge;import org.apache.flink.graph.Vertex;import org.apache.flink.types.NullValue;import org.apache.flink.util.Collector;import org.apache.log4j.Logger;import org.mappinganalysis.io.functions.BasicVertexCreator;import org.mappinganalysis.io.functions.FlinkEdgeCreator;import org.mappinganalysis.io.functions.FlinkPropertyMapper;import org.mappinganalysis.io.functions.PropertyCoGroupFunction;import org.mappinganalysis.model.FlinkProperty;import org.mappinganalysis.model.ObjectMap;import org.mappinganalysis.utils.Utils;import java.util.Locale;import java.util.ResourceBundle;/** * JDBC Data Loader for Flink */public class JDBCDataLoader {  private static final Logger LOG = Logger.getLogger(JDBCDataLoader.class);  private ExecutionEnvironment env;  private final ResourceBundle prop;  public JDBCDataLoader(ExecutionEnvironment env) {    this.env = env;    this.prop = ResourceBundle.getBundle(Utils.DB_PROPERY_FILE_NAME,        Locale.getDefault(),        Thread.currentThread().getContextClassLoader());  }  public DataSet<Vertex<Long, ObjectMap>> getVerticesFromJson(String vertexFile) throws Exception {    DataSet<Vertex<Long, ObjectMap>> vertices = env.readTextFile(vertexFile)        .map(new JsonToBasicVertexMapper());    vertices.collect();    return vertices;  }  /**   * Parses and transforms database entities to tuples.   *   * @return DataSet containing all vertices in the graph   */  @SuppressWarnings("unchecked")  public DataSet<Vertex<Long, ObjectMap>> getVertices(String fullDbName) throws Exception {    DataSet<Tuple3<Integer, String, String>> input        = env.createInput(JDBCInputFormat.buildJDBCInputFormat()            .setDrivername("com.mysql.jdbc.Driver")            .setDBUrl(prop.getString(fullDbName))            .setUsername(prop.getString("user"))            .setPassword(prop.getString("pw"))            .setQuery("select id, url, ontID_fk from concept where ontID_fk in " +                " ('http://dbpedia.org/', 'http://sws.geonames.org/', 'http://linkedgeodata.org/', " +                " 'http://data.nytimes.com/', 'http://rdf.freebase.com/')")            .finish(),        new TupleTypeInfo(Tuple3.class,            BasicTypeInfo.INT_TYPE_INFO,            BasicTypeInfo.STRING_TYPE_INFO,            BasicTypeInfo.STRING_TYPE_INFO)    );    DataSet<Vertex<Long, ObjectMap>> map = input.map(new BasicVertexCreator());    DataSet<FlinkProperty> properties = getProperties(fullDbName);    DataSet<Vertex<Long, ObjectMap>> group = properties.groupBy(0).reduceGroup(new PropertyVertexCreator());    return group.leftOuterJoin(map)        .where(0)        .equalTo(0)        .with(new FlatJoinFunction<Vertex<Long,ObjectMap>, Vertex<Long,ObjectMap>, Vertex<Long, ObjectMap>>() {          @Override          public void join(Vertex<Long, ObjectMap> left, Vertex<Long, ObjectMap> right, Collector<Vertex<Long, ObjectMap>> collector) throws Exception {            left.getValue().addProperty(Utils.DB_URL_FIELD, right.getValue().get(Utils.DB_URL_FIELD));            left.getValue().addProperty(Utils.ONTOLOGY, right.getValue().get(Utils.ONTOLOGY));            collector.collect(left);          }        });  }  /**   * Parses and transforms the properties to {@link FlinkProperty} tuples.   *   * @return DataSet containing all properties from database.   */  @SuppressWarnings("unchecked")  public DataSet<FlinkProperty> getProperties(String fullDbName) {    return env.createInput(JDBCInputFormat.buildJDBCInputFormat()            .setDrivername("com.mysql.jdbc.Driver")            .setDBUrl(prop.getString(fullDbName))            .setUsername(prop.getString("user"))            .setPassword(prop.getString("pw"))            .setQuery("select id, attName, attValue, attValueType from concept_attributes")            .finish(),        new TupleTypeInfo(Tuple4.class, BasicTypeInfo.INT_TYPE_INFO,            BasicTypeInfo.STRING_TYPE_INFO, BasicTypeInfo.STRING_TYPE_INFO,            BasicTypeInfo.STRING_TYPE_INFO)    ).map(new FlinkPropertyMapper()).withForwardedFields("f1;f2;f3");  }  /**   * Parses and transforms the db edges to {@link Edge} tuples.   *   * @return DataSet containing all edges from the database table.   */  @SuppressWarnings("unchecked")  public DataSet<Edge<Long, NullValue>> getEdges(String fullDbName) {    DataSet<Tuple2<Integer, Integer>> input        = env.createInput(JDBCInputFormat.buildJDBCInputFormat()            .setDrivername("com.mysql.jdbc.Driver")            .setDBUrl(prop.getString(fullDbName))            .setUsername(prop.getString("user"))            .setPassword(prop.getString("pw"))            .setQuery("select srcID, trgID from linksWithIDs")            .finish(),        new TupleTypeInfo(Tuple2.class,            BasicTypeInfo.INT_TYPE_INFO,            BasicTypeInfo.INT_TYPE_INFO)    );    return input.map(new FlinkEdgeCreator());  }  private static class PropertyVertexCreator implements GroupReduceFunction<FlinkProperty, Vertex<Long, ObjectMap>> {    private final Vertex<Long, ObjectMap> reuseVertex;    public PropertyVertexCreator() {      reuseVertex = new Vertex<>();      reuseVertex.setValue(new ObjectMap());    }    @Override    public void reduce(Iterable<FlinkProperty> properties, Collector<Vertex<Long, ObjectMap>> collector) throws Exception {      boolean isIdSet = false;      for (FlinkProperty property : properties) {        if (!isIdSet) {          reuseVertex.setId(property.getVertexId());          isIdSet = true;        }        Object value = property.getPropertyValue();        String key = property.getPropertyKey();        if (reuseVertex.getValue().containsKey(Utils.LAT) || reuseVertex.getValue().containsKey(Utils.LON)) {          continue;        }        if (property.getPropertyType().equals("double")) {          value = Doubles.tryParse(value.toString());        } else if (property.getPropertyType().equals("string")) {          value = value.toString();        }        reuseVertex.getValue().addProperty(key, value);      }      if (reuseVertex.getValue().containsKey(Utils.LABEL)) {        collector.collect(reuseVertex);      }    }  }}