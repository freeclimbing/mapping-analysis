package org.mappinganalysis;import com.google.common.collect.Lists;import com.google.common.primitives.Doubles;import org.apache.commons.cli.*;import org.apache.flink.api.common.ProgramDescription;import org.apache.flink.api.common.functions.*;import org.apache.flink.api.common.operators.Order;import org.apache.flink.api.java.DataSet;import org.apache.flink.api.java.ExecutionEnvironment;import org.apache.flink.api.java.LocalEnvironment;import org.apache.flink.api.java.operators.FilterOperator;import org.apache.flink.api.java.tuple.Tuple2;import org.apache.flink.configuration.Configuration;import org.apache.flink.graph.*;import org.apache.flink.types.NullValue;import org.apache.flink.util.Collector;import org.apache.log4j.Logger;import org.mappinganalysis.graph.ClusterComputation;import org.mappinganalysis.graph.FlinkConnectedComponents;import org.mappinganalysis.io.JDBCDataLoader;import org.mappinganalysis.io.functions.EdgeRestrictFlatJoinFunction;import org.mappinganalysis.io.functions.VertexRestrictFlatJoinFunction;import org.mappinganalysis.model.ObjectMap;import org.mappinganalysis.model.Preprocessing;import org.mappinganalysis.model.functions.*;import org.mappinganalysis.model.functions.preprocessing.CcIdAndCompTypeKeySelector;import org.mappinganalysis.model.functions.preprocessing.GenerateHashCcIdGroupReduceFunction;import org.mappinganalysis.model.functions.simcomputation.*;import org.mappinganalysis.model.functions.simsort.*;import org.mappinganalysis.model.functions.stats.ResultComponentSelectionFilter;import org.mappinganalysis.model.functions.stats.ResultEdgesSelectionFilter;import org.mappinganalysis.model.functions.stats.ResultVerticesSelectionFilter;import org.mappinganalysis.model.functions.typegroupby.TypeGroupBy;import org.mappinganalysis.utils.Stats;import org.mappinganalysis.utils.TypeDictionary;import org.mappinganalysis.utils.Utils;import java.util.*;/** * Mapping analysis example */public class MappingAnalysisExample implements ProgramDescription {  private static final Logger LOG = Logger.getLogger(MappingAnalysisExample.class);  private static ExecutionEnvironment env;// = ExecutionEnvironment.getExecutionEnvironment();  /**   * Command line options   */  private static final String OPTION_DELETE_LINKS_PREPROCESSING = "dlp";  private static final String OPTION_PRE_CLUSTER_FILTER = "pcf";  private static final String OPTION_ONLY_INITIAL_CLUSTER = "oic";//  private static final String OPTION_REPRESENTATIVE_STRATEGY = "rs";  private static final String OPTION_DATA_SET_NAME = "ds";  private static final String OPTION_WRITE_STATS = "ws";  private static final String OPTION_CLUSTER_STATS = "cs";  private static final String OPTION_IGNORE_MISSING_PROPERTIES = "imp";  private static boolean IS_LINK_FILTER_ACTIVE;  private static boolean STOP_AFTER_INITIAL_CLUSTERING;  private static boolean PRINT_STATS;  private static List<Long> CLUSTER_STATS;  private static Options OPTIONS;  static {    OPTIONS = new Options();    OPTIONS.addOption(OPTION_DATA_SET_NAME, "dataset-name", true,        "Choose one of the datasets [" + Utils.CMD_GEO + " (default), " + Utils.CMD_LL + "].");    OPTIONS.addOption(OPTION_DELETE_LINKS_PREPROCESSING, "delete-links-preprocessing", false,        "Use delete 1:n strategy for initial link check (default: false).");    OPTIONS.addOption(OPTION_PRE_CLUSTER_FILTER, "pre-cluster-filter", true,        "Specify preprocessing filter strategy for entity properties ["            + Utils.CMD_COMBINED + " (default), geo, label, type]");    OPTIONS.addOption(OPTION_IGNORE_MISSING_PROPERTIES, "ignore-missing-properties", false,        "Do not penalize missing properties on resources in similarity computation process (default: false).");    OPTIONS.addOption(OPTION_ONLY_INITIAL_CLUSTER, "only-initial-cluster", false,        "Don't compute final clusters, stop after preprocessing (default: false).");//    OPTIONS.addOption(OPTION_REPRESENTATIVE_STRATEGY, "representative-strategy",//        true, "Set strategy to determine cluster representative (currently only best datasource (default))");    OPTIONS.addOption(OPTION_WRITE_STATS, "write-stats", false,        "Write statistics to output (default: false).");    Option clusterStats = new Option(OPTION_CLUSTER_STATS, "cluster-stats", true,        "Be more verbose while processing specified cluster ids.");    clusterStats.setArgs(Option.UNLIMITED_VALUES);    OPTIONS.addOption(clusterStats);  }  /**   * main program   * @param args cmd args   * @throws Exception   */  public static void main(String[] args) throws Exception {    Configuration conf = new Configuration();    conf.setLong("taskmanager.network.numberOfBuffers", 65536L);    env =  new LocalEnvironment(conf);    CommandLine cmd = parseArguments(args);    if (cmd == null) {      return;    }    String dataset;    final String optionDataset = cmd.getOptionValue(OPTION_DATA_SET_NAME);    if (optionDataset != null && optionDataset.equals(Utils.CMD_LL)) {      dataset = Utils.LL_FULL_NAME;    } else {      dataset = Utils.GEO_FULL_NAME;    }    IS_LINK_FILTER_ACTIVE = cmd.hasOption(OPTION_DELETE_LINKS_PREPROCESSING);    Utils.IGNORE_MISSING_PROPERTIES = cmd.hasOption(OPTION_IGNORE_MISSING_PROPERTIES);    Utils.PRE_CLUSTER_STRATEGY = cmd.getOptionValue(OPTION_PRE_CLUSTER_FILTER, Utils.CMD_COMBINED);    STOP_AFTER_INITIAL_CLUSTERING = cmd.hasOption(OPTION_ONLY_INITIAL_CLUSTER);    PRINT_STATS = cmd.hasOption(OPTION_WRITE_STATS);    String[] clusterStats = cmd.getOptionValues(OPTION_CLUSTER_STATS);    if (clusterStats != null) {      CLUSTER_STATS = Utils.convertWsSparatedString(clusterStats);    }    /**     * 0. Get data     */    final Graph<Long, ObjectMap, NullValue> graph = getInputGraph(dataset);    execute(graph);  }  /**   * Mapping analysis computation   * @param preprocGraph input graph   * @throws Exception   */  private static void execute(Graph<Long, ObjectMap, NullValue> preprocGraph) throws Exception {    /**     * [1] PREPROCESSING     */    LOG.info("[1] PREPROCESSING");//    preprocGraph = Preprocessing.applyLinkFilterStrategy(preprocGraph, env, IS_LINK_FILTER_ACTIVE);    preprocGraph = Preprocessing.applyTypeToInternalTypeMapping(preprocGraph, env);//    preprocGraph = Preprocessing.applyTypeMissMatchCorrection(preprocGraph);    /**     * [2] INITIAL MATCHING     * - apply similarity functions, similarities are added as edge value and merged     * (if more than one similarity)     */    LOG.info("[2] INITIAL MATCHING");//    Graph<Long, ObjectMap, NullValue> allEdgesGraph = createAllEdgesGraph(preprocGraph);    /**     * [3] INITIAL CLUSTERING     * - connected components + split     */    LOG.info("[3] INITIAL CLUSTERING");    preprocGraph = addCcIdsToGraph(preprocGraph);    DataSet<Edge<Long, ObjectMap>> edges = SimCompUtility.computeEdgeSimWithVertices(preprocGraph);    DataSet<Vertex<Long, ObjectMap>> vertices = preprocGraph.getVertices()        .map(new AddShadingTypeMapFunction())        .groupBy(new CcIdAndCompTypeKeySelector())        .reduceGroup(new GenerateHashCcIdGroupReduceFunction());    Graph<Long, ObjectMap, ObjectMap> graph = Graph.fromDataSet(vertices, edges, env);//    List<Long> ccList1 = Lists.newArrayList(10L, 60L);//    writeCcToLog(graph, ccList1);//    LOG.info("### end part: ");//    writeEdgesToLog(graph, ccList1);////    DataSet<Vertex<Long, ObjectMap>> filter = graph.getVertices().filter(new FilterFunction<Vertex<Long, ObjectMap>>() {//      @Override//      public boolean filter(Vertex<Long, ObjectMap> vertex) throws Exception {//        if (vertex.getId() == 10L || vertex.getId() == 60L) {//          return true;//        } else {//          return false;//        }//      }//    });////    for (int i = 0; i < 10; i++) {//      DataSet<Vertex<Long, ObjectMap>> test = filter;//      for (Vertex<Long, ObjectMap> vertex : test.collect()) {//        LOG.info("vertex: " + vertex);//        Long hash = Utils.getHash(vertex.getId().toString());//        vertex.getValue().put(Utils.HASH_CC, hash);//        LOG.info("hash: " + hash);//      }//    }    /*     * TypeGroupBy: internally compType is used, afterwards typeIntern is used again.     */    Graph<Long, ObjectMap, ObjectMap> typeGroupByGraph        = new TypeGroupBy().execute(graph, 5);    Graph<Long, ObjectMap, ObjectMap> two        = new TypeGroupBy().execute(graph, 5);//    Graph<Long, ObjectMap, ObjectMap> three//        = new TypeGroupBy().execute(two, 1);//    Graph<Long, ObjectMap, ObjectMap> four//        = new TypeGroupBy().execute(three, 1);//    Graph<Long, ObjectMap, ObjectMap> five//        = new TypeGroupBy().execute(four, 1);    /*     * SimSort     */    Graph<Long, ObjectMap, ObjectMap> simSortGraph = SimSort.prepare(graph, env);    double minClusterSim = 0.75D;    simSortGraph = SimSort.execute(simSortGraph, 200, minClusterSim);    Graph<Long, ObjectMap, ObjectMap> simSortGraph2 = SimSort.prepare(graph, env);    simSortGraph2 = SimSort.execute(simSortGraph2, 200, minClusterSim);    // TODO vertices with -2 as aggSimValue needs to get a new unique hash ccid    if (STOP_AFTER_INITIAL_CLUSTERING) {      if (PRINT_STATS) {        LOG.info("### Statistics: ");//        Stats.countPrintGeoPointsPerOntology(preprocGraph);//        LOG.info("#####");//        LOG.info("##### 1. part: ");////        for (Vertex<Long, ObjectMap> vertex : simSortGraph.getVertices().sortPartition(0, Order.ASCENDING).first(500).collect()) {//          LOG.info(vertex);//        }//        LOG.info("#####");//        LOG.info("##### 2. part");//        for (Vertex<Long, ObjectMap> vertex : simSortGraph2.getVertices().sortPartition(0, Order.ASCENDING).first(500).collect()) {//          LOG.info(vertex);//        }//        LOG.info("#####");//        LOG.info("#####");//        List<Long> ccList = Lists.newArrayList(284L);//        LOG.info("### pre verts: ");//        Stats.writeCcToLog(graph, ccList, Utils.CC_ID);////        LOG.info("### verts: ");//        Stats.writeCcToLog(simSortGraph, ccList, Utils.CC_ID);//        for (Vertex<Long, ObjectMap> vertex : simSortGraph.filterOnVertices(new FilterFunction<Vertex<Long, ObjectMap>>() {//          @Override//          public boolean filter(Vertex<Long, ObjectMap> vertex) throws Exception {//            if ((long) vertex.getValue().get(Utils.HASH_CC) == 3163811415109580695L//                || (long) vertex.getValue().get(Utils.HASH_CC) == 3902953758034310605L//                || (long) vertex.getValue().get(Utils.HASH_CC) == 817252051449788998L) {//              return true;//            } else {//              return false;//            }//          }//        }).getVertices().collect()) {//          LOG.info(vertex);//        }//        LOG.info("### edges: ");//        Stats.writeEdgesToLog(graph, ccList);        simSortGraph = simSortGraph.filterOnVertices(new FilterFunction<Vertex<Long, ObjectMap>>() {          @Override          public boolean filter(Vertex<Long, ObjectMap> vertex) throws Exception {              return vertex.getValue().containsKey(Utils.VERTEX_STATUS);          }        });        for (int i = 0; i < 20; i++) {          LOG.info("vertex_status_false  " + simSortGraph.getVertices().count());        }//        LOG.info("vertex_status_false  " + simSortGraph.getVertices().count());//        simSortGraph.filterOnVertices(new FilterFunction<Vertex<Long, ObjectMap>>() {//          @Override//          public boolean filter(Vertex<Long, ObjectMap> vertex) throws Exception {//            if (Doubles.compare((double) vertex.getValue().get(Utils.VERTEX_AGG_SIM_VALUE), -2D) == 0) {//              return true;//            } else {//              return false;//            }//          }//        });//        LOG.info("=-2  " + simSortGraph.getVertices().count());////        LOG.info("#####");//        LOG.info("##### FINAL OUT");//        LOG.info("#####");//        for (Vertex<Long, ObjectMap> vertex : typeGroupByGraph.getVertices().sortPartition(0, Order.ASCENDING).first(500).collect()) {//          LOG.info(vertex);//        }////        LOG.info("#####");//        LOG.info("#####");//        LOG.info("#####");//        for (Vertex<Long, ObjectMap> vertex : two.getVertices().sortPartition(0, Order.ASCENDING).first(500).collect()) {//          LOG.info(vertex);//        }//        DataSet<Tuple2<Long, Long>> result = typeGroupByGraph.getVertices()//            .map(new MapFunction<Vertex<Long, ObjectMap>, Tuple2<Long, Long>>() {//              @Override//              public Tuple2<Long, Long> map(Vertex<Long, ObjectMap> vertex) throws Exception {//                return new Tuple2<>((long) vertex.getValue().get(Utils.HASH_CC), 1L);//              }//            }).groupBy(0).reduceGroup(new GroupReduceFunction<Tuple2<Long, Long>, Tuple2<Long, Long>>() {//              @Override//              public void reduce(Iterable<Tuple2<Long, Long>> iterable, Collector<Tuple2<Long, Long>> collector) throws Exception {//                long result = 0;//                long id = 0;//                for (Tuple2<Long, Long> tuple1 : iterable) {//                  result += tuple1.f1;//                  id = tuple1.f0;//                }//                collector.collect(new Tuple2<>(id, result));//              }//            });////        LOG.info("tuple count: " + result.count());////        DataSet<Tuple2<Long, Long>> bar = two.getVertices()//            .map(new MapFunction<Vertex<Long, ObjectMap>, Tuple2<Long, Long>>() {//              @Override//              public Tuple2<Long, Long> map(Vertex<Long, ObjectMap> vertex) throws Exception {//                return new Tuple2<>((long) vertex.getValue().get(Utils.HASH_CC), 1L);//              }//            }).groupBy(0).reduceGroup(new GroupReduceFunction<Tuple2<Long, Long>, Tuple2<Long, Long>>() {//              @Override//              public void reduce(Iterable<Tuple2<Long, Long>> iterable, Collector<Tuple2<Long, Long>> collector) throws Exception {//                long result = 0;//                long id = 0;//                for (Tuple2<Long, Long> tuple1 : iterable) {//                  result += tuple1.f1;//                  id = tuple1.f0;//                }//                collector.collect(new Tuple2<>(id, result));//              }//            });////        LOG.info("tuple count: " + bar.count());////        Stats.countPrintResourcesPerCc(components1);//        Stats.printAccumulatorValues(env, aggVertexSimGraph.getEdgeIds());//        LOG.info("first: " + iterateInputGraph.getVertexIds().count());//        LOG.info("sec: " + aggVertexSimGraph.getVertices()//            .filter(new FilterFunction<Vertex<Long, ObjectMap>>() {//              @Override//              public boolean filter(Vertex<Long, ObjectMap> vertex) throws Exception {//                return !(boolean) vertex.getValue().get(Utils.VERTEX_STATUS);//              }//            }).count());////        Stats.countPrintResourcesPerCc(unionVerts.map(new MapFunction<Vertex<Long, ObjectMap>, Tuple2<Long, Long>>() {//          @Override//          public Tuple2<Long, Long> map(Vertex<Long, ObjectMap> vertex) throws Exception {//            return new Tuple2<>(vertex.getId(), (long) vertex.getValue().get(Utils.CC_ID));//          }//        }));//        LOG.info("lowSim: " + lowSimVertices.count());//        LOG.info("low 0.6: " + lowSimVertices.filter(new LowSimFilterFunction(0.6)).count());//        LOG.info("low 0.7: " + lowSimVertices.filter(new LowSimFilterFunction(0.7)).count());//        newVertices.print();            // TODO//        // get low confidence vertices//        DataSet<Vertex<Long, ObjectMap>> aggVertexFilter = aggVertices//            .filter(new FilterFunction<Vertex<Long, ObjectMap>>() {//              @Override//              public boolean filter(Vertex<Long, ObjectMap> vertex) throws Exception {//                ObjectMap properties = vertex.getValue();//                if (properties.containsKey(Utils.VERTEX_AGG_SIM_VALUE)) {//                  if ((double) properties.get(Utils.VERTEX_AGG_SIM_VALUE) < 0.6) {//                    return true;//                  }//                }//                return false;//              }//            });//        aggVertexFilter.map(new MapFunction<Vertex<Long,ObjectMap>, Tuple2<Long, Integer>>() {//          @Override//          public Tuple2<Long, Integer> map(Vertex<Long, ObjectMap> vertex) throws Exception {//            return new Tuple2<>((long) vertex.getValue().get(Utils.CC_ID), 1);//          }//        }).groupBy(0).aggregate(Aggregations.SUM, 1).print();//        System.out.println("eddges #########################");////        aggVertexSimGraph.getEdges().filter(new FilterFunction<Edge<Long, ObjectMap>>() {//          List<Long> edgeIds = Arrays.asList(414L, 1974L, 413L, 1213L, 6502L, 7490L, 6501L);//          @Override//          public boolean filter(Edge<Long, ObjectMap> edge) throws Exception {//            return edgeIds.contains(edge.getSource()) || edgeIds.contains(edge.getTarget());//          }//        }).print();//        System.out.println("v1 #########################");//        round1.getVertices().filter(new FilterFunction<Vertex<Long, ObjectMap>>() {//          @Override//          public boolean filter(Vertex<Long, ObjectMap> vertex) throws Exception {//            return vertex.getValue().containsKey(Utils.CC_ID) && (//                (long) vertex.getValue().get(Utils.CC_ID) == 4744L ||//                    (long) vertex.getValue().get(Utils.CC_ID) == 6501L ||//                    (long) vertex.getValue().get(Utils.CC_ID) == 413L);//          }//        }).print();//        System.out.println("v2 #########################");//        round2.getVertices().filter(new FilterFunction<Vertex<Long, ObjectMap>>() {//          @Override//          public boolean filter(Vertex<Long, ObjectMap> vertex) throws Exception {//            return vertex.getValue().containsKey(Utils.CC_ID) && (//                (long) vertex.getValue().get(Utils.CC_ID) == 4744L ||//                    (long) vertex.getValue().get(Utils.CC_ID) == 6501L ||//                    (long) vertex.getValue().get(Utils.CC_ID) == 413L);//          }//        }).print();////        LOG.info(lowSimVertices1.count());//        LOG.info(lowSimVertices2.count());            //TODO//        printEdgesSimValueBelowThreshold(allEdgesGraph, accumulatedSimValues);      }    }    /**     * 4. Determination of cluster representative     * - currently: entity from best "data source" (GeoNames > DBpedia > others)     *///    final DataSet<Vertex<Long, ObjectMap>> mergedCluster = graph.getVertices()//        .groupBy(new CcIdKeySelector())//        .reduceGroup(new BestDataSourceAllLabelsGroupReduceFunction());////    if (PRINT_STATS) {////      Stats.countPrintResourcesPerCc(components);//      Stats.printLabelsForMergedClusters(mergedCluster);//    }    /**     * 5. Cluster Refinement     *///    mergedCluster.filter(new FilterFunction<Vertex<Long, ObjectMap>>() {//      @Override//      public boolean filter(Vertex<Long, ObjectMap> vertex) throws Exception {//         return !(vertex.getValue().get(Utils.CL_VERTICES) instanceof Set);//      }//    });////    DataSet<Edge<Long, Double>> edgesCrossedClusters = mergedCluster//        .cross(mergedCluster)//        .with(new ClusterEdgeCreationCrossFunction())//        .filter(new FilterFunction<Edge<Long, Double>>() {//          @Override//          public boolean filter(Edge<Long, Double> edge) throws Exception {//            return edge.getValue() > 0.7;//          }//        });//    if (PRINT_STATS) {//      edgesCrossedClusters.print();////      System.out.println(edgesCrossedClusters.count());//    }  }  private static Graph<Long, ObjectMap, NullValue> addCcIdsToGraph(      Graph<Long, ObjectMap, NullValue> graph) throws Exception {    final DataSet<Long> ccInputVertices = graph.getVertices()        .map(new CcVerticesCreator());    final DataSet<Tuple2<Long, Long>> components = FlinkConnectedComponents        .compute(ccInputVertices, graph.getEdgeIds(), 1000);    return graph.joinWithVertices(components, new CcIdVertexJoinFunction());  }  private static Graph<Long, ObjectMap, NullValue> createAllEdgesGraph(      Graph<Long, ObjectMap, NullValue> graph) throws Exception {    final DataSet<Edge<Long, NullValue>> allEdges = ClusterComputation        .computeComponentEdges(addCcIdsToGraph(graph).getVertices(), true);    return Graph.fromDataSet(graph.getVertices(), allEdges, env);  }  /**   * Create the input graph for further analysis,   * restrict to edges where source and target are in vertices set.   * @return graph with vertices and edges.   * @throws Exception   * @param fullDbString complete server+port+db string   */  public static Graph<Long, ObjectMap, NullValue> getInputGraph(String fullDbString)      throws Exception {    JDBCDataLoader loader = new JDBCDataLoader(env);    DataSet<Vertex<Long, ObjectMap>> vertices = loader.getVertices(fullDbString);    // restrict edges to these where source and target are vertices    DataSet<Edge<Long, NullValue>> edges = loader.getEdges(fullDbString)        .leftOuterJoin(vertices)        .where(0).equalTo(0)        .with(new EdgeRestrictFlatJoinFunction())        .leftOuterJoin(vertices)        .where(1).equalTo(0)        .with(new EdgeRestrictFlatJoinFunction());    // delete vertices without any edges due to restriction    DataSet<Vertex<Long, ObjectMap>> left = vertices        .leftOuterJoin(edges)        .where(0).equalTo(0)        .with(new VertexRestrictFlatJoinFunction()).distinct(0);    DataSet<Vertex<Long, ObjectMap>> finalVertices = vertices        .leftOuterJoin(edges)        .where(0).equalTo(1)        .with(new VertexRestrictFlatJoinFunction()).distinct(0)        .union(left);    return Graph.fromDataSet(finalVertices, edges, env);  }  /**   * Parses the program arguments or returns help if args are empty.   *   * @param args program arguments   * @return command line which can be used in the program   */  private static CommandLine parseArguments(String[] args) throws ParseException {    if (args.length == 0) {      HelpFormatter formatter = new HelpFormatter();      formatter.printHelp(MappingAnalysisExample.class.getName(), OPTIONS, true);      return null;    }    CommandLineParser parser = new BasicParser();    return parser.parse(OPTIONS, args);  }  @Override  public String getDescription() {    return MappingAnalysisExample.class.getName();  }  public static class AddAggSimVertexJoinFunction implements JoinFunction<Vertex<Long, ObjectMap>, Tuple2<Long, Double>, Vertex<Long, ObjectMap>> {    @Override    public Vertex<Long, ObjectMap> join(Vertex<Long, ObjectMap> vertex, Tuple2<Long, Double> tuple) throws Exception {      vertex.getValue().put(Utils.VERTEX_AGG_SIM_VALUE, tuple.f1);      return vertex;    }  }  public static class LowSimFilterFunction implements FilterFunction<Vertex<Long, ObjectMap>> {    private final double threshold;    public LowSimFilterFunction(double t) {      this.threshold = t;    }    @Override    public boolean filter(Vertex<Long, ObjectMap> vertex) throws Exception {      return (double) vertex.getValue().get(Utils.VERTEX_AGG_SIM_VALUE) < threshold;    }  }  private static class AddShadingTypeMapFunction implements MapFunction<Vertex<Long, ObjectMap>, Vertex<Long, ObjectMap>> {    @Override    public Vertex<Long, ObjectMap> map(Vertex<Long, ObjectMap> vertex) throws Exception {      String vertexType = vertex.getValue().get(Utils.TYPE_INTERN).toString();      if (TypeDictionary.TYPE_SHADINGS.containsKey(vertexType)          || TypeDictionary.TYPE_SHADINGS.containsValue(vertexType)) {        switch (vertexType) {          case "School":            vertexType = "ArchitecturalStructure";            break;          case "Mountain":            vertexType = "Island";            break;          case "Settlement":          case "Country":            vertexType = "AdministrativeRegion";            break;        }      }      vertex.getValue().put(Utils.COMP_TYPE, vertexType);      return vertex;    }  }}