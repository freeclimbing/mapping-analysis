package org.mappinganalysis;import com.google.common.collect.Lists;import com.google.common.collect.Maps;import org.apache.commons.cli.*;import org.apache.flink.api.common.ProgramDescription;import org.apache.flink.api.common.functions.*;import org.apache.flink.api.java.DataSet;import org.apache.flink.api.java.ExecutionEnvironment;import org.apache.flink.api.java.LocalEnvironment;import org.apache.flink.api.java.functions.KeySelector;import org.apache.flink.api.java.tuple.Tuple2;import org.apache.flink.configuration.Configuration;import org.apache.flink.graph.*;import org.apache.flink.graph.spargel.MessageIterator;import org.apache.flink.graph.spargel.MessagingFunction;import org.apache.flink.graph.spargel.VertexCentricConfiguration;import org.apache.flink.graph.spargel.VertexUpdateFunction;import org.apache.flink.types.NullValue;import org.apache.flink.util.Collector;import org.apache.log4j.Logger;import org.mappinganalysis.graph.ClusterComputation;import org.mappinganalysis.graph.FlinkConnectedComponents;import org.mappinganalysis.io.JDBCDataLoader;import org.mappinganalysis.io.functions.EdgeRestrictFlatJoinFunction;import org.mappinganalysis.io.functions.VertexRestrictFlatJoinFunction;import org.mappinganalysis.model.ObjectMap;import org.mappinganalysis.model.Preprocessing;import org.mappinganalysis.model.functions.*;import org.mappinganalysis.model.functions.representative.BestDataSourceAllLabelsGroupReduceFunction;import org.mappinganalysis.model.functions.representative.ClusterEdgeCreationCrossFunction;import org.mappinganalysis.model.functions.simcomputation.EmptyGeoCodeFilter;import org.mappinganalysis.model.functions.simcomputation.GeoCodeSimMapper;import org.mappinganalysis.model.functions.simcomputation.TrigramSimilarityMapper;import org.mappinganalysis.model.functions.simcomputation.TypeSimilarityMapper;import org.mappinganalysis.model.functions.simsort.AggSimValueEdgeMapFunction;import org.mappinganalysis.model.functions.simsort.TripletToEdgeMapFunction;import org.mappinganalysis.utils.Stats;import org.mappinganalysis.utils.Utils;import java.util.*;/** * Mapping analysis example */public class MappingAnalysisExample implements ProgramDescription {  private static final Logger LOG = Logger.getLogger(MappingAnalysisExample.class);  private static ExecutionEnvironment env;// = ExecutionEnvironment.getExecutionEnvironment();  /**   * Command line options   */  private static final String OPTION_DELETE_LINKS_PREPROCESSING = "dlp";  private static final String OPTION_PRE_CLUSTER_FILTER = "pcf";  private static final String OPTION_ONLY_INITIAL_CLUSTER = "oic";//  private static final String OPTION_REPRESENTATIVE_STRATEGY = "rs";  private static final String OPTION_DATA_SET_NAME = "ds";  private static final String OPTION_WRITE_STATS = "ws";  private static final String OPTION_CLUSTER_STATS = "cs";  private static boolean IS_LINK_FILTER_ACTIVE;  private static String PRE_CLUSTER_STRATEGY;  private static boolean STOP_AFTER_INITIAL_CLUSTERING;  private static boolean PRINT_STATS;  private static List<Long> CLUSTER_STATS;  private static Options OPTIONS;  static {    OPTIONS = new Options();    OPTIONS.addOption(OPTION_DATA_SET_NAME, "dataset-name", true,        "Choose one of the datasets [" + Utils.CMD_GEO + " (default), " + Utils.CMD_LL + "].");    OPTIONS.addOption(OPTION_DELETE_LINKS_PREPROCESSING, "delete-links-preprocessing", false,        "Use delete 1:n strategy for initial link check (default: false).");    OPTIONS.addOption(OPTION_PRE_CLUSTER_FILTER, "pre-cluster-filter", true,        "Specify preprocessing filter strategy for entity properties ["            + Utils.CMD_COMBINED + " (default), geo, label, type]");    OPTIONS.addOption(OPTION_ONLY_INITIAL_CLUSTER, "only-initial-cluster", false,        "Don't compute final clusters, stop after preprocessing (default: false).");//    OPTIONS.addOption(OPTION_REPRESENTATIVE_STRATEGY, "representative-strategy",//        true, "Set strategy to determine cluster representative (currently only best datasource (default))");    OPTIONS.addOption(OPTION_WRITE_STATS, "write-stats", false,        "Write statistics to output (default: false).");    Option clusterStats = new Option(OPTION_CLUSTER_STATS, "cluster-stats", true,        "Be more verbose while processing specified cluster ids.");    clusterStats.setArgs(Option.UNLIMITED_VALUES);    OPTIONS.addOption(clusterStats);  }  /**   * main program   * @param args cmd args   * @throws Exception   */  public static void main(String[] args) throws Exception {    Configuration conf = new Configuration();    conf.setLong("taskmanager.network.numberOfBuffers", 65536L);    env =  new LocalEnvironment(conf);    CommandLine cmd = parseArguments(args);    if (cmd == null) {      return;    }    String dataset;    final String optionDataset = cmd.getOptionValue(OPTION_DATA_SET_NAME);    if (optionDataset != null && optionDataset.equals(Utils.CMD_LL)) {      dataset = Utils.LL_FULL_NAME;    } else {      dataset = Utils.GEO_FULL_NAME;    }    IS_LINK_FILTER_ACTIVE = cmd.hasOption(OPTION_DELETE_LINKS_PREPROCESSING);    PRE_CLUSTER_STRATEGY = cmd.getOptionValue(OPTION_PRE_CLUSTER_FILTER, Utils.CMD_COMBINED);    STOP_AFTER_INITIAL_CLUSTERING = cmd.hasOption(OPTION_ONLY_INITIAL_CLUSTER);    PRINT_STATS = cmd.hasOption(OPTION_WRITE_STATS);    String[] clusterStats = cmd.getOptionValues(OPTION_CLUSTER_STATS);    if (clusterStats != null) {      CLUSTER_STATS = Utils.convertWsSparatedString(clusterStats);    }    /**     * 0. Get data     */    final Graph<Long, ObjectMap, NullValue> graph = getInputGraph(dataset);    execute(graph);  }  /**   * Mapping analysis computation   * @param preprocGraph input graph   * @throws Exception   */  private static void execute(Graph<Long, ObjectMap, NullValue> preprocGraph) throws Exception {    /**     * [1] PREPROCESSING     */    LOG.info("[1] PREPROCESSING");//    preprocGraph = Preprocessing.applyLinkFilterStrategy(preprocGraph, env, IS_LINK_FILTER_ACTIVE);    preprocGraph = Preprocessing.applyTypeToInternalTypeMapping(preprocGraph, env);    preprocGraph = Preprocessing.applyTypeMissMatchCorrection(preprocGraph);    /**     * [2] INITIAL MATCHING     * - apply similarity functions, similarities are added as edge value and merged     * (if more than one similarity)     */    LOG.info("[2] INITIAL MATCHING");//    Graph<Long, ObjectMap, NullValue> allEdgesGraph = createAllEdgesGraph(preprocGraph);//    LOG.info("All edges computed, new graph created.");    /**     * [3] INITIAL CLUSTERING     * - connected components + split     */    LOG.info("[3] INITIAL CLUSTERING");    preprocGraph = addCcIdsToGraph(preprocGraph);    DataSet<Edge<Long, ObjectMap>> edges = addSimilaritiesToEdges(preprocGraph);    DataSet<Vertex<Long, ObjectMap>> vertices = preprocGraph.getVertices()        .groupBy(new CcIdAndTypeKeySelector())        .reduceGroup(new GenerateNewCcIdGroupReduceFunction());    Graph<Long, ObjectMap, ObjectMap> graph = Graph.fromDataSet(vertices, edges, env);    VertexCentricConfiguration parameters = new VertexCentricConfiguration();    parameters.setName("Type-based Cluster Generation Iteration");    parameters.setDirection(EdgeDirection.ALL);    // assign non-type vertices to best matching    Graph<Long, ObjectMap, ObjectMap> oneIterationGraph = graph.runVertexCentricIteration(        new NoTypeVertexUpdateFunction(),        new VertexAndSimValueMessagingFunction(), 100, parameters);//    Graph<Long, ObjectMap, ObjectMap> secIterationGraph = oneIterationGraph.runVertexCentricIteration(//        new NoTypeVertexUpdateFunction(),//        new VertexAndSimValueMessagingFunction(), 1, parameters);//    Graph<Long, ObjectMap, ObjectMap> triIterationGraph = secIterationGraph.runVertexCentricIteration(//        new NoTypeVertexUpdateFunction(),//        new VertexAndSimValueMessagingFunction(), 1, parameters);//    Graph<Long, ObjectMap, ObjectMap> fIterationGraph = triIterationGraph.runVertexCentricIteration(//        new NoTypeVertexUpdateFunction(),//        new VertexAndSimValueMessagingFunction(), 1, parameters);//    Graph<Long, ObjectMap, ObjectMap> ffIterationGraph = fIterationGraph.runVertexCentricIteration(//        new NoTypeVertexUpdateFunction(),//        new VertexAndSimValueMessagingFunction(), 1, parameters);//    Graph<Long, ObjectMap, ObjectMap> tenIterationGraph = ffIterationGraph.runVertexCentricIteration(//        new NoTypeVertexUpdateFunction(),//        new VertexAndSimValueMessagingFunction(), 5, parameters);////    Graph<Long, ObjectMap, ObjectMap> difference = fIterationGraph.difference(ffIterationGraph);    // iteration to flag vertices based on low aggregated edge similarity//    Graph<Long, ObjectMap, ObjectMap> gsaGraph = graph//        .mapVertices(new ActivateAllVerticesMapFunction())//        .runGatherSumApplyIteration(//            new GatherEdgeSimsBasedOnVertexStatusFunction(),//            new SumEdgeSimsAndCountFunction(),//            new ApplyVertexAggSimChangeVertexStatusFunction(0.6), 100);////    DataSet<Vertex<Long, ObjectMap>> lowSimVertices = gsaGraph.getVertices()//        .filter(new FilterFunction<Vertex<Long, ObjectMap>>() {//          @Override//          public boolean filter(Vertex<Long, ObjectMap> vertex) throws Exception {//            return !(boolean) vertex.getValue().get(Utils.VERTEX_STATUS);//          }//        });//    aggVertexSimGraph = aggVertexSimGraph.removeVertices(lowSimVertices.collect());////    // find max ccId over all vertices (should always be only one,//    // because only one vertex of each (unique) component can be deleted)//    final long maxCcId = components.aggregate(Aggregations.MAX, 1).collect().get(0).f1;////    // take old vertex id as base ccId and add the previously found max ccId to have unique values//    DataSet<Vertex<Long, ObjectMap>> newVertices = lowSimVertices//        .map(new MapFunction<Vertex<Long, ObjectMap>, Vertex<Long, ObjectMap>>() {//          @Override//          public Vertex<Long, ObjectMap> map(Vertex<Long, ObjectMap> vertex) throws Exception {//            ObjectMap value = vertex.getValue();//            value.put(Utils.CC_ID, (long) value.get(Utils.CC_ID) + maxCcId);//            return vertex;//          }//        });////    DataSet<Vertex<Long, ObjectMap>> unionVerts = aggVertexSimGraph.getVertices().union(newVertices);////    Graph<Long, ObjectMap, ObjectMap> unionGraph//        = Graph.fromDataSet(unionVerts, aggVertexSimGraph.getEdges(), env);//    List<Vertex<Long, ObjectMap>> bla = newVertices.collect();//    aggVertexSimGraph = aggVertexSimGraph.addVertices(bla);    if (STOP_AFTER_INITIAL_CLUSTERING) {      if (PRINT_STATS) {        LOG.info("### Statistics: ");//        writeEdgesToLog(graph, CLUSTER_STATS);        LOG.info("### 1. part: ");        DataSet<Tuple2<Long, Long>> components1 = oneIterationGraph.getVertices()            .map(new ComponentsMapFunction());        Stats.countPrintResourcesPerCc(components1);        LOG.info("CC:");        List<Long> ccList = Lists.newArrayList(-2174664030895378318L, -5245716776948673147L);        writeCcToLog(oneIterationGraph, ccList);        LOG.info("Vertices: ");        writeVerticesToLog(oneIterationGraph, CLUSTER_STATS);//        LOG.info("### 2. part: ");//        DataSet<Tuple2<Long, Long>> components2 = secIterationGraph.getVertices()//            .map(new ComponentsMapFunction());//        Stats.countPrintResourcesPerCc(components2);//        writeVerticesToLog(secIterationGraph, CLUSTER_STATS);////        LOG.info("### 3. part: ");//        DataSet<Tuple2<Long, Long>> components3 = triIterationGraph.getVertices()//            .map(new ComponentsMapFunction());//        Stats.countPrintResourcesPerCc(components3);//        writeVerticesToLog(triIterationGraph, CLUSTER_STATS);////        LOG.info("### 4. part: ");//        DataSet<Tuple2<Long, Long>> components4 = fIterationGraph.getVertices()//            .map(new ComponentsMapFunction());//        Stats.countPrintResourcesPerCc(components4);//        writeVerticesToLog(fIterationGraph, CLUSTER_STATS);////        LOG.info("### 5. part: ");//        DataSet<Tuple2<Long, Long>> components5 = ffIterationGraph.getVertices()//            .map(new ComponentsMapFunction());//        Stats.countPrintResourcesPerCc(components5);//        writeVerticesToLog(ffIterationGraph, CLUSTER_STATS);////        LOG.info("### 6. part: ");//        DataSet<Tuple2<Long, Long>> components10 = tenIterationGraph.getVertices()//            .map(new ComponentsMapFunction());//        Stats.countPrintResourcesPerCc(components10);//        writeVerticesToLog(tenIterationGraph, CLUSTER_STATS);////        difference.getVertices().print();//        Stats.printAccumulatorValues(env, aggVertexSimGraph.getEdgeIds());//        LOG.info("first: " + iterateInputGraph.getVertexIds().count());//        LOG.info("sec: " + aggVertexSimGraph.getVertices()//            .filter(new FilterFunction<Vertex<Long, ObjectMap>>() {//              @Override//              public boolean filter(Vertex<Long, ObjectMap> vertex) throws Exception {//                return !(boolean) vertex.getValue().get(Utils.VERTEX_STATUS);//              }//            }).count());////        Stats.countPrintResourcesPerCc(unionVerts.map(new MapFunction<Vertex<Long, ObjectMap>, Tuple2<Long, Long>>() {//          @Override//          public Tuple2<Long, Long> map(Vertex<Long, ObjectMap> vertex) throws Exception {//            return new Tuple2<>(vertex.getId(), (long) vertex.getValue().get(Utils.CC_ID));//          }//        }));//        LOG.info("lowSim: " + lowSimVertices.count());//        LOG.info("low 0.6: " + lowSimVertices.filter(new LowSimFilterFunction(0.6)).count());//        LOG.info("low 0.7: " + lowSimVertices.filter(new LowSimFilterFunction(0.7)).count());//        newVertices.print();        // TODO//        // get low confidence vertices//        DataSet<Vertex<Long, ObjectMap>> aggVertexFilter = aggVertices//            .filter(new FilterFunction<Vertex<Long, ObjectMap>>() {//              @Override//              public boolean filter(Vertex<Long, ObjectMap> vertex) throws Exception {//                ObjectMap properties = vertex.getValue();//                if (properties.containsKey(Utils.VERTEX_AGG_SIM_VALUE)) {//                  if ((double) properties.get(Utils.VERTEX_AGG_SIM_VALUE) < 0.6) {//                    return true;//                  }//                }//                return false;//              }//            });//        aggVertexFilter.map(new MapFunction<Vertex<Long,ObjectMap>, Tuple2<Long, Integer>>() {//          @Override//          public Tuple2<Long, Integer> map(Vertex<Long, ObjectMap> vertex) throws Exception {//            return new Tuple2<>((long) vertex.getValue().get(Utils.CC_ID), 1);//          }//        }).groupBy(0).aggregate(Aggregations.SUM, 1).print();//        System.out.println("eddges #########################");////        aggVertexSimGraph.getEdges().filter(new FilterFunction<Edge<Long, ObjectMap>>() {//          List<Long> edgeIds = Arrays.asList(414L, 1974L, 413L, 1213L, 6502L, 7490L, 6501L);//          @Override//          public boolean filter(Edge<Long, ObjectMap> edge) throws Exception {//            return edgeIds.contains(edge.getSource()) || edgeIds.contains(edge.getTarget());//          }//        }).print();//        System.out.println("v1 #########################");//        round1.getVertices().filter(new FilterFunction<Vertex<Long, ObjectMap>>() {//          @Override//          public boolean filter(Vertex<Long, ObjectMap> vertex) throws Exception {//            return vertex.getValue().containsKey(Utils.CC_ID) && (//                (long) vertex.getValue().get(Utils.CC_ID) == 4744L ||//                    (long) vertex.getValue().get(Utils.CC_ID) == 6501L ||//                    (long) vertex.getValue().get(Utils.CC_ID) == 413L);//          }//        }).print();//        System.out.println("v2 #########################");//        round2.getVertices().filter(new FilterFunction<Vertex<Long, ObjectMap>>() {//          @Override//          public boolean filter(Vertex<Long, ObjectMap> vertex) throws Exception {//            return vertex.getValue().containsKey(Utils.CC_ID) && (//                (long) vertex.getValue().get(Utils.CC_ID) == 4744L ||//                    (long) vertex.getValue().get(Utils.CC_ID) == 6501L ||//                    (long) vertex.getValue().get(Utils.CC_ID) == 413L);//          }//        }).print();////        LOG.info(lowSimVertices1.count());//        LOG.info(lowSimVertices2.count());        //TODO//        printEdgesSimValueBelowThreshold(allEdgesGraph, accumulatedSimValues);      }      return;    }    /**     * 4. Determination of cluster representative     * - currently: entity from best "data source" (GeoNames > DBpedia > others)     */    final DataSet<Vertex<Long, ObjectMap>> mergedCluster = graph.getVertices()        .groupBy(new CcIdKeySelector())        .reduceGroup(new BestDataSourceAllLabelsGroupReduceFunction());    if (PRINT_STATS) {//      Stats.countPrintResourcesPerCc(components);      Stats.printLabelsForMergedClusters(mergedCluster);    }    /**     * 5. Cluster Refinement     */    mergedCluster.filter(new FilterFunction<Vertex<Long, ObjectMap>>() {      @Override      public boolean filter(Vertex<Long, ObjectMap> vertex) throws Exception {         return !(vertex.getValue().get(Utils.CL_VERTICES) instanceof Set);      }    });    DataSet<Edge<Long, Double>> edgesCrossedClusters = mergedCluster        .cross(mergedCluster)        .with(new ClusterEdgeCreationCrossFunction())        .filter(new FilterFunction<Edge<Long, Double>>() {          @Override          public boolean filter(Edge<Long, Double> edge) throws Exception {            return edge.getValue() > 0.7;          }        });    if (PRINT_STATS) {      edgesCrossedClusters.print();//      System.out.println(edgesCrossedClusters.count());    }  }  private static void writeEdgesToLog(Graph<Long, ObjectMap, ObjectMap> oneIterationGraph,                                      List<Long> clusterStats) throws Exception {    oneIterationGraph.filterOnEdges(new ResultEdgesSelectionFilter(clusterStats))        .getEdges().collect();  }  private static void writeVerticesToLog(Graph<Long, ObjectMap, ObjectMap> graph,                                         List<Long> clusterList) throws Exception {    graph.filterOnVertices(new ResultVerticesSelectionFilter(clusterList))        .getVertices().collect();  }  private static void writeCcToLog(Graph<Long, ObjectMap, ObjectMap> graph,                                   List<Long> clusterList) throws Exception {    graph.filterOnVertices(new ResultComponentSelectionFilter(clusterList))        .getVertices().collect();  }  private static DataSet<Edge<Long, ObjectMap>> addSimilaritiesToEdges(Graph<Long, ObjectMap, NullValue> preprocGraph) {    LOG.info("Start computing edge similarities...");    final DataSet<Triplet<Long, ObjectMap, ObjectMap>> accumulatedSimValueTriplets        = computeSimilarities(preprocGraph.getTriplets(), PRE_CLUSTER_STRATEGY);    LOG.info("Done.");    return accumulatedSimValueTriplets        .map(new TripletToEdgeMapFunction())        .map(new AggSimValueEdgeMapFunction());  }  private static Graph<Long, ObjectMap, NullValue> addCcIdsToGraph(Graph<Long, ObjectMap, NullValue> preprocGraph) throws Exception {    final DataSet<Long> ccInputVertices = preprocGraph.getVertices().map(new CcVerticesCreator());    final DataSet<Tuple2<Long, Long>> components = FlinkConnectedComponents        .compute(ccInputVertices, preprocGraph.getEdgeIds(), 1000);    return preprocGraph        .joinWithVertices(components, new CcIdVertexJoinFunction());  }  /**   * optional stats method   */  private static void printEdgesSimValueBelowThreshold(Graph<Long, ObjectMap, NullValue> allGraph,                                                       DataSet<Triplet<Long, ObjectMap, ObjectMap>>                                                           accumulatedSimValues) throws Exception {    LOG.info("accum sim values: " + accumulatedSimValues.count());    DataSet<Edge<Long, NullValue>> edgesNoSimValue = allGraph.getEdges()        .leftOuterJoin(accumulatedSimValues)        .where(0, 1).equalTo(0, 1)        .with(new FlatJoinFunction<Edge<Long, NullValue>, Triplet<Long, ObjectMap, ObjectMap>,            Edge<Long, NullValue>>() {          @Override          public void join(Edge<Long, NullValue> edge, Triplet<Long, ObjectMap, ObjectMap> triplet,                           Collector<Edge<Long, NullValue>> collector) throws Exception {            if (triplet == null) {              collector.collect(edge);            }          }        });    // print vertex information for start and target vertex    edgesNoSimValue        .leftOuterJoin(allGraph.getVertices())        .where(0).equalTo(0)        .with(new JoinFunction<Edge<Long, NullValue>, Vertex<Long, ObjectMap>,            Triplet<Long, ObjectMap, NullValue>>() {          @Override          public Triplet<Long, ObjectMap, NullValue> join(Edge<Long, NullValue> edge,                                                          Vertex<Long, ObjectMap> vertex) throws Exception {            return new Triplet<>(edge.getSource(), edge.getTarget(), vertex.getValue(), new ObjectMap(),                NullValue.getInstance());          }        })        .leftOuterJoin(allGraph.getVertices())        .where(1).equalTo(0)        .with(new JoinFunction<Triplet<Long, ObjectMap, NullValue>, Vertex<Long, ObjectMap>, Triplet<Long, ObjectMap,            NullValue>>() {          @Override          public Triplet<Long, ObjectMap, NullValue> join(Triplet<Long, ObjectMap, NullValue> triplet,                                                          Vertex<Long, ObjectMap> vertex) throws Exception {            triplet.f3 = vertex.getValue();            return triplet;          }        })        .print();  }  private static Graph<Long, ObjectMap, NullValue> createAllEdgesGraph(      Graph<Long, ObjectMap, NullValue> graph) throws Exception {    final DataSet<Edge<Long, NullValue>> allEdges = ClusterComputation        .computeComponentEdges(addCcIdsToGraph(graph).getVertices(), true);    return Graph.fromDataSet(graph.getVertices(), allEdges, env);  }  public static DataSet<Triplet<Long, ObjectMap, ObjectMap>> computeSimilarities(DataSet<Triplet<Long, ObjectMap,      NullValue>> triplets, String filter) {    LOG.info("Started: compute similarities...");    switch (filter) {      case "geo":        return basicGeoSimilarity(triplets);      case "label":        return basicTrigramSimilarity(triplets);      case "type":        return basicTypeSimilarity(triplets);      default:        return joinDifferentSimilarityValues(basicGeoSimilarity(triplets),            basicTrigramSimilarity(triplets),            basicTypeSimilarity(triplets));    }  }  /**   * Join several sets of triplets which are being produced within property similarity computation.   * Edges where no similarity value is higher than the appropriate threshold are not in the result set.   * @param tripletDataSet intput datasets   * @return joined dataset with all similarities in an ObjectMap   */  @SafeVarargs  private static DataSet<Triplet<Long, ObjectMap, ObjectMap>> joinDifferentSimilarityValues(      DataSet<Triplet<Long, ObjectMap, ObjectMap>>... tripletDataSet) {    DataSet<Triplet<Long, ObjectMap, ObjectMap>> triplets = null;    boolean isFirstSet = false;    for (DataSet<Triplet<Long, ObjectMap, ObjectMap>> dataSet : tripletDataSet) {      if (!isFirstSet) {        triplets = dataSet;        isFirstSet = true;      } else {        triplets = triplets            .fullOuterJoin(dataSet)            .where(0, 1)            .equalTo(0, 1)            .with(new FullOuterJoinSimilarityValueFunction());      }    }    return triplets;  }  private static DataSet<Triplet<Long, ObjectMap, ObjectMap>> basicTypeSimilarity(      DataSet<Triplet<Long, ObjectMap, NullValue>> triplets) {    return triplets        .map(new TypeSimilarityMapper());  }  private static DataSet<Triplet<Long, ObjectMap, ObjectMap>> basicTrigramSimilarity(      DataSet<Triplet<Long, ObjectMap, NullValue>> triplets) {    return triplets        .map(new TrigramSimilarityMapper());  }  private static DataSet<Triplet<Long, ObjectMap, ObjectMap>> basicGeoSimilarity(      DataSet<Triplet<Long, ObjectMap, NullValue>> triplets) {    return triplets        .filter(new EmptyGeoCodeFilter())        .map(new GeoCodeSimMapper());  }  /**   * Create the input graph for further analysis,   * restrict to edges where source and target are in vertices set.   * @return graph with vertices and edges.   * @throws Exception   * @param fullDbString complete server+port+db string   */  public static Graph<Long, ObjectMap, NullValue> getInputGraph(String fullDbString)      throws Exception {    JDBCDataLoader loader = new JDBCDataLoader(env);    DataSet<Vertex<Long, ObjectMap>> vertices = loader.getVertices(fullDbString);    // restrict edges to these where source and target are vertices    DataSet<Edge<Long, NullValue>> edges = loader.getEdges(fullDbString)        .leftOuterJoin(vertices)        .where(0).equalTo(0)        .with(new EdgeRestrictFlatJoinFunction())        .leftOuterJoin(vertices)        .where(1).equalTo(0)        .with(new EdgeRestrictFlatJoinFunction());    // delete vertices without any edges due to restriction    DataSet<Vertex<Long, ObjectMap>> left = vertices        .leftOuterJoin(edges)        .where(0).equalTo(0)        .with(new VertexRestrictFlatJoinFunction()).distinct(0);    DataSet<Vertex<Long, ObjectMap>> finalVertices = vertices        .leftOuterJoin(edges)        .where(0).equalTo(1)        .with(new VertexRestrictFlatJoinFunction()).distinct(0)        .union(left);    return Graph.fromDataSet(finalVertices, edges, env);  }  /**   * Parses the program arguments or returns help if args are empty.   *   * @param args program arguments   * @return command line which can be used in the program   */  private static CommandLine parseArguments(String[] args) throws ParseException {    if (args.length == 0) {      HelpFormatter formatter = new HelpFormatter();      formatter.printHelp(MappingAnalysisExample.class.getName(), OPTIONS, true);      return null;    }    CommandLineParser parser = new BasicParser();    return parser.parse(OPTIONS, args);  }  @Override  public String getDescription() {    return MappingAnalysisExample.class.getName();  }  public static class AddAggSimVertexJoinFunction implements JoinFunction<Vertex<Long, ObjectMap>, Tuple2<Long, Double>, Vertex<Long, ObjectMap>> {    @Override    public Vertex<Long, ObjectMap> join(Vertex<Long, ObjectMap> vertex, Tuple2<Long, Double> tuple) throws Exception {      vertex.getValue().put(Utils.VERTEX_AGG_SIM_VALUE, tuple.f1);      return vertex;    }  }  public static class LowSimFilterFunction implements FilterFunction<Vertex<Long, ObjectMap>> {    private final double threshold;    public LowSimFilterFunction(double t) {      this.threshold = t;    }    @Override    public boolean filter(Vertex<Long, ObjectMap> vertex) throws Exception {      return (double) vertex.getValue().get(Utils.VERTEX_AGG_SIM_VALUE) < threshold;    }  }  private static class ResultVerticesSelectionFilter implements FilterFunction<Vertex<Long, ObjectMap>> {    private final List<Long> clusterList;    public ResultVerticesSelectionFilter(List<Long> clusterList) {      this.clusterList = clusterList;    }    @Override    public boolean filter(Vertex<Long, ObjectMap> vertex) throws Exception {      if (clusterList.contains(vertex.getId())) {        LOG.info(Utils.toLog(vertex));        return true;      } else {        return false;      }    }  }  private static class GenerateNewCcIdGroupReduceFunction implements GroupReduceFunction<Vertex<Long, ObjectMap>, Vertex<Long, ObjectMap>> {    @Override    public void reduce(Iterable<Vertex<Long, ObjectMap>> vertices,                       Collector<Vertex<Long, ObjectMap>> collector) throws Exception {      Long hash = null;      for (Vertex<Long, ObjectMap> vertex : vertices) {        if (hasNoType(vertex)) {          vertex.getValue().put(Utils.HASH_CC, Utils.getHash(vertex.getId().toString()));        } else {          if (hash == null) {            hash = Utils.getHash(vertex.getValue().get(Utils.TYPE_INTERN).toString()                .concat(vertex.getValue().get(Utils.CC_ID).toString()));          }          vertex.getValue().put(Utils.HASH_CC, hash);        }        collector.collect(vertex);      }    }    private boolean hasNoType(Vertex<Long, ObjectMap> vertex) {      return vertex.getValue().get(Utils.TYPE_INTERN).equals(Utils.NO_TYPE_AVAILABLE)          || vertex.getValue().get(Utils.TYPE_INTERN).equals(Utils.NO_VALUE);    }  }  private static class CcIdAndTypeKeySelector implements KeySelector<Vertex<Long, ObjectMap>, Tuple2<Long, String>> {    @Override    public Tuple2<Long, String> getKey(Vertex<Long, ObjectMap> vertex) throws Exception {      return new Tuple2<>((long) vertex.getValue().get(Utils.CC_ID),          vertex.getValue().get(Utils.TYPE_INTERN).toString());    }  }  private static class NoTypeVertexUpdateFunction extends VertexUpdateFunction<Long, ObjectMap, ObjectMap> {    @Override    public void updateVertex(Vertex<Long, ObjectMap> vertex,                             MessageIterator<ObjectMap> inMessages) throws Exception {      if (!vertex.getValue().containsKey(Utils.TMP_TYPE) && hasNoType(vertex.getValue())) {        ObjectMap maxCcIdMap = null;        // save already existing sim values        HashMap<Long, Double> options;        if (vertex.getValue().containsKey(Utils.VERTEX_OPTIONS)) {          options = (HashMap<Long, Double>) vertex.getValue().get(Utils.VERTEX_OPTIONS);        } else {          options = Maps.newHashMap();        }        // get max sim from neighbors + vertex        double bestSim = 0.0;        for (ObjectMap msg : inMessages) {          long vertexCcId = (long) vertex.getValue().get(Utils.HASH_CC);          long neighborCcId = (long) msg.get(Utils.HASH_CC);          if (vertexCcId != neighborCcId) {            double newSim = (double) msg.get(Utils.AGGREGATED_SIM_VALUE);            options.put((long) msg.get(Utils.VERTEX_ID), newSim);            if (newSim > bestSim) {              bestSim = newSim;              if (msg.containsKey(Utils.TMP_TYPE) || !hasNoType(msg)) {                maxCcIdMap = msg;              } else if (hasNoType(msg)) {                maxCcIdMap = neighborCcId < vertexCcId ? msg : vertex.getValue();              }            }          } else {            // cc is equal, neighbor options could have better similarity ...            if (msg.containsKey(Utils.VERTEX_OPTIONS)) {              HashMap<Long, Double> tmp = (HashMap<Long, Double>) msg.get(Utils.VERTEX_OPTIONS);              for (Long key : tmp.keySet()) {                options.put(key, tmp.get(key));              }//              LOG.info(tmp.toString());            }            // ... but both values cannot be next option, because already in same cc            options.remove(vertex.getId());            options.remove(msg.get(Utils.VERTEX_ID));          }        }        // if neighbor is already in cc, neighbors of neighbors may be interesting        for (Long key : options.keySet()) {          if (options.get(key).equals(Collections.max(options.values()))) {            for (ObjectMap msg : inMessages) {              if (msg.get(Utils.VERTEX_ID).equals(key)) {                maxCcIdMap = msg;              }            }          }        }        // save new cc_id on vertex        if (maxCcIdMap != null) {//              if (!options.containsKey(maxCcIdVertex.getId())) {          vertex.getValue().put(Utils.HASH_CC, maxCcIdMap.get(Utils.HASH_CC));          vertex.getValue().put(Utils.VERTEX_OPTIONS, options);          if (maxCcIdMap.containsKey(Utils.TMP_TYPE)) {            vertex.getValue().put(Utils.TMP_TYPE, maxCcIdMap.get(Utils.TMP_TYPE));          }          if (maxCcIdMap.containsKey(Utils.TYPE_INTERN)) {            vertex.getValue().put(Utils.TMP_TYPE, maxCcIdMap.get(Utils.TYPE_INTERN));          }          // TODO vert id          setNewVertexValue(vertex.getValue());          // updatevertex//                } else {//                  options.)//                }        } else {//                LOG.info("No ");        }      }    }    private boolean hasNoType(ObjectMap map) {      return map.get(Utils.TYPE_INTERN).equals(Utils.NO_TYPE_AVAILABLE)          || map.get(Utils.TYPE_INTERN).equals(Utils.NO_VALUE);    }  }  private static class VertexAndSimValueMessagingFunction extends MessagingFunction<Long, ObjectMap, ObjectMap, ObjectMap> {    @Override    public void sendMessages(Vertex<Long, ObjectMap> vertex) throws Exception {      for (Edge<Long, ObjectMap> edge : getEdges()) {        vertex.getValue().put(Utils.AGGREGATED_SIM_VALUE, edge.getValue().get(Utils.AGGREGATED_SIM_VALUE));        vertex.getValue().put(Utils.VERTEX_ID, vertex.getId());        if ((long) vertex.getId() == edge.getSource()) {          sendMessageTo(edge.getTarget(), vertex.getValue());        } else {          sendMessageTo(edge.getSource(), vertex.getValue());        }      }    }  }  private static class ResultEdgesSelectionFilter implements FilterFunction<Edge<Long, ObjectMap>> {    private final List<Long> clusterList;    public ResultEdgesSelectionFilter(List<Long> clusterStats) {      this.clusterList = clusterStats;    }    @Override    public boolean filter(Edge<Long, ObjectMap> edge) throws Exception {      if (clusterList.contains(edge.getSource()) && clusterList.contains(edge.getTarget())) {        LOG.info(Utils.toLog(edge));        return true;      } else {        return false;      }    }  }  private static class ComponentsMapFunction implements MapFunction<Vertex<Long, ObjectMap>, Tuple2<Long, Long>> {    @Override    public Tuple2<Long, Long> map(Vertex<Long, ObjectMap> vertex) throws Exception {      return new Tuple2<>(vertex.getId(), (long) vertex.getValue().get(Utils.HASH_CC));    }  }  private static class ResultComponentSelectionFilter implements FilterFunction<Vertex<Long, ObjectMap>> {    private final List<Long> clusterList;    public ResultComponentSelectionFilter(List<Long> clusterList) {      this.clusterList = clusterList;    }    @Override    public boolean filter(Vertex<Long, ObjectMap> vertex) throws Exception {      if (vertex.getValue().containsKey(Utils.HASH_CC)          && clusterList.contains(vertex.getValue().get(Utils.HASH_CC))) {        LOG.info(Utils.toLog(vertex));        return true;      } else {        return false;      }    }  }//  private static class ChangeCcIdMapFunction implements MapFunction<Vertex<Long, ObjectMap>, Vertex<Long, ObjectMap>> {//    @Override//    public Vertex<Long, ObjectMap> map(Vertex<Long, ObjectMap> vertex) throws Exception {//      ObjectMap value = vertex.getValue();//      value.put(Utils.CC_ID, value.get(Utils.CC_ID) + maxCcId);//      return vertex;//    }//  }}